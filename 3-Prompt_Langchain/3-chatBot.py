# Builiding on Console only No GUI : 
# from langchain_huggingface import ChatHuggingFace , HuggingFaceEndpoint
# from dotenv import load_dotenv 

# load_dotenv()

# llm = HuggingFaceEndpoint(model="mistralai/Mistral-7B-Instruct-v0.3" , max_new_tokens=10)

# model = ChatHuggingFace(llm=llm)

# while True: 
#     user_input = input("You: ")
#     if(user_input == "exit"):
#         break 
#     result = model.invoke(user_input)
#     print("AI: " , result.content)
    
    
# Now the problem in this code is it not storing the history of prompts 
# Ex: Which is greater 2 or 0 
# : Now multiply bigger number with 100 : So in this case it will not give desired output.
# We have to maintain the context.

# from langchain_huggingface import ChatHuggingFace , HuggingFaceEndpoint
# from dotenv import load_dotenv 

# load_dotenv()

# llm = HuggingFaceEndpoint(model="mistralai/Mistral-7B-Instruct-v0.3" , max_new_tokens=10)

# model = ChatHuggingFace(llm=llm)

# chatHistory = []

# while True: 
#     user_input = input("You: ")
#     chatHistory.append(user_input)
#     if(user_input == "exit"):
#         break 
#     result = model.invoke(chatHistory)
#     chatHistory.append(result.content)
#     print("AI: " , result.content.strip())
    
    
# Problem:
# While maintaining the chat history, it is currently unclear which messages were sent by the user and which were generated by the AI. This lack of role distinction can lead to confusion and negatively impact the quality of context-aware responses.

# Langchain Solution: 

from langchain_huggingface import ChatHuggingFace , HuggingFaceEndpoint
from dotenv import load_dotenv 
from langchain_core.messages import HumanMessage , SystemMessage , AIMessage

load_dotenv()

llm = HuggingFaceEndpoint(model="mistralai/Mistral-7B-Instruct-v0.3" , max_new_tokens=10)

model = ChatHuggingFace(llm=llm)

chatHistory = [
    SystemMessage(content="You are a helpful assistant.")
]

while True: 
    user_input = input("You: ")
    chatHistory.append(HumanMessage(content=user_input))
    if(user_input == "exit"):
        break 
    result = model.invoke(chatHistory)
    chatHistory.append(AIMessage(content=result.content))
    print("AI: " , result.content.strip())